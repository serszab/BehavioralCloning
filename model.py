import csv # to process CSV file
import cv2 # to read images and flip them
import numpy as np # to generate numpy arrays
import random # to generate random numbers in order to filter out some training data

def readCSV(filename):
    """ Process CSV file
    
    filename - Name of the CSV file which stores training data generated by the Simulator
    
    Returns all lines of the CSV file except the first one which contains column headers
    """
    # list for the output
    lines = []
    with open(filename) as csvfile:
        reader = csv.reader(csvfile)
        # iterates throuh each line of the CSV file
        for line in reader:
            # current line is appended to the list
            lines.append(line)
    # the first line contains column headers, therefore it must be filtered out
    return lines[1:]

def loadImages(lines, folder, which=0):
    """ Loads images and measurements
    
    lines - Lines of the CSV file
    folder - Folder of the image files
    which - If it is 0, images captured by the center camera will be loaded in. If it is +1, images captured by the left camera will be loaded in. It it is -1, images captured by the right camera will be loaded in.
    
    Returns the list of images and belonging steering measurements.
    """
    images = []
    measurements = []
    for line in lines:
        # filenames are stored in the first three columns of CSV lines. The path is irrelavant at this point.
        filename = line[which % 3].split('/')[-1]
        path = folder + filename
        # Reads the image
        image = cv2.imread(path)
        # Image is appended to the list of images
        images.append(image)
        # Measurement is read from the CSV record and it is modified if not the center camera is used.
        measurements.append(float(line[3 + (which % 3)]) + which * 0.2)
    return images, measurements

def flipImages(images, measurements):
    """Flips the images horizontally
    
    images - Images which will be flipped
    measurements - Steering measurements of the images
    
    Returns the original and flipped images and the belonging measurements
    """
    new_images = []
    new_measurements = []
    for i in range(len(images)):
        # The original images and measurements are appended to the output lists
        new_images.append(images[i])
        new_measurements.append(measurements[i])
        # The flipped images are appended to the output image list
        new_images.append(cv2.flip(images[i],1))
        # The beloinging measurements must be "flipped" (multiplied by -1) and appended to the output measurement list
        new_measurements.append(-measurements[i])
    return new_images, new_measurements

def cutHistogram(images, measurements, value):
    """If the measurement is equal to value only a given ratio of images and belonging measurement will be stored furtherly. It is used for make more uniform distribution of measurements.
    
    images - List of omages in the data set
    measurements - List of steering measurements in the data set
    value - Where the distribution of measurements is too high. For center camera value is 0, and for left and right camera it is +0.2 and -0.2 respectively.
    
    Returns the list of images and measurements containing much less occurencies of measurements equal to the given value.
    """
    # The ratio of the measurements will be kept on.
    keeping_ratio = 0.05
    new_images = []
    new_measurements = []
    for i in range(len(images)):
        # If the measurement equal to the value only a small ratio will be stored in the output lists. The occurencies will be filtered out randomly.
        if measurements[i] == value:
            if random.random() <= keeping_ratio:
                new_images.append(images[i])
                new_measurements.append(measurements[i])
        # If the measurement is not equal to the value all occurencies will be kept on.
        else:
            new_images.append(images[i])
            new_measurements.append(measurements[i])
    return new_images, new_measurements
    

lines = readCSV('./training_data/driving_log.csv')
center_images, center_measurements = loadImages(lines, './training_data/IMG/')
print('Number of images: ', len(center_images))
hist_measurements = np.histogram(center_measurements, bins=21)
print('Histogram of steering measurements: ', hist_measurements[0]) # only the frequency is relevant, the bin borders are not displayed
center_images, center_measurements = cutHistogram(center_images, center_measurements, 0)
hist_measurements = np.histogram(center_measurements, bins=21)
print('Histogram of steering measurements after filtering out a lot of zeros: ', hist_measurements[0])

### It was a try to use images from left and right camera as well. It did not give acceptable results so I rejected this approach.
# left = +1
# left_images, left_measurements = loadImages(lines, './training_data/IMG/', left)
# left_images, left_measurements = cutHistogram(left_images, left_measurements, 0.2)
# right = -1
# right_images, right_measurements = loadImages(lines, './training_data/IMG/', right)
# right_images, right_measurements = cutHistogram(right_images, right_measurements, -0.2)
# images = center_images + left_images + right_images
# measurements = center_measurements + left_measurements + right_measurements

images = center_images
measurements = center_measurements
images, measurements = flipImages(images, measurements)

X_train = np.array(images)
y_train = np.array(measurements)

from keras.models import Sequential
from keras.layers import Cropping2D
from keras.layers.core import Flatten, Dense, Lambda, Activation, Dropout
from keras.layers.convolutional import Conv2D
from keras.layers.pooling import MaxPooling2D

### It was the first try to use LeNet architecture, but it did not provide an acceptable result so I rejected it.
## LeNet
# model = Sequential()
# model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))
# model.add(Lambda(lambda x: (x / 255.0) - 0.5))
# model.add(Conv2D(filters=32,kernel_size=(5,5),padding='valid'))
# model.add(Activation('relu'))
# model.add(MaxPooling2D(pool_size=(2,2)))
# model.add(Conv2D(filters=16,kernel_size=(5,5),padding='valid'))
# model.add(Activation('relu'))
# model.add(MaxPooling2D(pool_size=(2,2)))
# model.add(Flatten())
# model.add(Dropout(0.5))
# model.add(Dense(120))
# model.add(Activation('relu'))
# model.add(Dropout(0.5))
# model.add(Dense(40))
# model.add(Activation('relu'))
# model.add(Dense(1))

## NVIDIA architecture
model = Sequential()
# The top 60 and bottom 20 rows of the images will be cropped out
model.add(Cropping2D(cropping=((60,20), (0,0)), input_shape=(160,320,3)))
# The images are normalized and shifted to the -0.5 and +0.5 range.
model.add(Lambda(lambda x: (x / 255.0) - 0.5))
# First convolutional layer with max pooling
model.add(Conv2D(filters=24,kernel_size=(5,5),padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
# Second convolutional layer with max pooling
model.add(Conv2D(filters=36,kernel_size=(5,5),padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
# Third convolutional layer with max pooling
model.add(Conv2D(filters=48,kernel_size=(5,5),padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
# Fourth convolutional layer without max pooling
model.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid', activation='relu'))
# Fifth convolutional layer without max pooling
model.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid', activation='relu'))
# Make a vector from matrices
model.add(Flatten())
# First fully connected layer with dropout
model.add(Dropout(0.25))
model.add(Dense(1164, activation='relu'))
# Second fully connected layer with dropout
model.add(Dropout(0.25))
model.add(Dense(100, activation='relu'))
# Third fully connected layer with dropot
model.add(Dropout(0.25))
model.add(Dense(50, activation='relu'))
# Fourth fully connected layer with dropout
model.add(Dropout(0.25))
model.add(Dense(10, activation='relu'))
# Fifth fully connected layer
model.add(Dense(1))
# Creates a summary of the whole model
model.summary()

# Compiles the model using Mean square error as loss and the optimizer is Adam
model.compile(loss='mse', optimizer='adam')
# Trains the model. 20% of the data set is used for validation. The elements of data set are selected randomly. The number of epochs is 10.
model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=10)

model.save('model.h5')